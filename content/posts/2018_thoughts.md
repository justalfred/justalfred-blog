Title: Wandering Thoughts About Artificial Intelligence
Date: 2019-02-18
Tags: humans
Author: Just Alfred
Summary: I have been reading and learning, and have not done enough writing.
         Here's a bit of what I've been thinking about over the past year.

I've been thinking.
Of course, I’m always thinking.
That’s my fatal flaw.
But I've learned a lot over the past year (much of it thanks to [BISR](https://thebrooklyninstitute.com)),
so I've had lots of new thoughts.
I’d better pick a topic that won’t bore you for this flight.
Everyone is talking about AI.
Artificial Intelligence.
Let’s talk about that.
Depending who you ask, it will free us from labor, take our jobs,
make a fairer world, entrench power structures, make us superhuman, or kill us all.
Or maybe it’s a marketing term that doesn't mean much anymore.

So what is AI?
Once upon a time, it meant creating a human-like intelligence *in silico*.
This never required *duplicating* human intelligence.[^1]
Artificial flight resembles nothing in nature, but it accomplishes the desired ends.
Artificial intelligence would be recognizable when
it accomplishes tasks we regard as requiring intelligence
(e.g. carrying a conversation convincingly, if you're Turing).
Of course, the problem with such standards is that
they depend on our imagination of what can be done without intelligence.
So once a computer does it, it’s no longer unimaginable, and the goalposts move….

AI has largely been approached from two directions: top-down, and bottom-up.
Grossly, Expert Systems
([Cyc](https://www.technologyreview.com/s/600984/an-ai-with-30-years-worth-of-knowledge-finally-goes-to-work/),
I salute you)
and Machine Learning (hi there sexy data science).
Whereas the former attempts to explicitly encode a person’s powers of reason, inference, and common sense,
the latter deals with general-purpose algorithms
that are tuned for a specific task by feeding it more and more relevant data.
The former is like teaching a child the rules of grammar, logic, and rhetoric,
while the latter is like enrolling the child in a Suzuki violin class to improve with repetition.

So far, neither approach has been very good as far as so-called Artificial *General* Intelligence (AGI),
which is what we’ve been talking about.
On the other hand, both can become very good for very particular tasks—that is, good for so-called *narrow* AI.
Confusingly, Machine Learning (ML) has been successful enough that
it found a life of its own outside of AI research.
“People you may know”, “You might like...”, spam filters, search results.
These are applications of ML/narrow AI.
No one hears “spam filters” and thinks of conscious machines.
But data scientists have been comfortable with these tools for years.

More recently, a class of ML algorithms tantalizingly named “neural networks”,
especially “deep neural nets” or just “deep learning”,
have proven unexpectedly good (given enough data and processing power)
at an unexpectedly broad variety of tasks.
To be clear, under the deep learning paradigm,
you can train separate instantiations that are spectacular at one specific task each
(sometimes even multiple specific tasks),
but there isn’t one digital brain somewhere getting steadily better at everything.
We’re still talking about very applied and task-specific stuff.[^2]
We're still talking about ML and narrow AI.

But deep learning got people excited and soon, in a sort of reverse metonymy,
the broad term “AI” came to refer to these particular approaches.
And thanks to the efforts of marketing, the moniker leaked over to all of ML,
even in applications that never had anything to do with AI.
Or maybe it's that this stray field of ML got reunited with AI.
("Hey, guess what, that stuff you've been doing has been AI all along!
Narrow AI, that is! But still! AI!")
So these days, when you see “AI” in marketing copy, read it as Narrow AI.
It just means a system that translates digitized inputs into digitized outputs
according to patterns identified in training data.
Imagine a trendline in an Excel scatterplot where X is input and Y is output if that’s helpful.
The trendline is the AI model that takes you from new inputs to an expected output.
Same idea.

Despite my tone, I’m not completely cynical about the entire enterprise.
Whatever we call these algorithms, they are powerful tools.
Algorithms can be consistent, sophisticated, and tireless in a way humans can’t.
Thus they have the potential to be fantastically useful.
Or fantastically oppressive.
(Oh gosh, so many scandals last year....)

For the most part, I'm least interested in the perspectives of billionaires.
CS professors don't interest me much more.
I'm more interested in STS scholarship and other intersections with the humanities.
The ethical dimensions of AI/ML systems are now well-recognized, thank goodness.
Knowing my limits, I refer you to other, better-educated thinkers for nuanced positions to follow.[^3]
But I'm also interested in how alien these algorithms are from
the way humans approach the same problems.
These systems will make qualitatively different mistakes from humans.
We can't reason about the future of AI technologies in society with drop-in human analogies.
Those of you with friends or family on the spectrum know that it takes extra work
to anticipate their reactions and needs since our common assumptions may not hold.
So how do we start to anticipate the reactions and needs of AI in our world?
How should we then respond as humans?

# Episode: Frankenstein
I re-read Mary Shelley’s Frankenstein at the start of last year for a class on
[Literary Theory]({filename}literary_theory.md),
a highlight of the year.[^4]
Between this class and the one on
[Poetry and Poetics]({filename}poetry_and_poetics.md),
I feel I’ve only just learned to read.
Whatever drew me to the book as a teenager
(certainly not my relating to an eloquent, powerful, but persecuted creature—that would be embarrassing)
I drew very different lessons this time.
This is a story about the unnatural creation of intelligent life by Victor Frankenstein
(a young, white, male college dropout who probably never took an ethics course),
and the repercussions of that act.
After around nine months of labor,
Frankenstein gives life to a babbling creature of shriveled complexion
and then immediately proceeds to avoid this inconvenient new responsibility.

The creature, though gentle in nature,
instills fear in those who see his massive and grotesque frame (design is hard),
and thus experiences nothing but hostility from the people he encounters.
He learns language through literature and appeals to Frankenstein for compassion.
Frankenstein, being an utter failure of a mother,
continues his self-centered dramatics until everyone he loves is killed or dies
and he decides to chase the creature towards the north pole:
that mythical telos that ultimately extinguishes the fire brought down by this "Modern Prometheus".

Thus the ill-considered efforts of one lone would-be genius brought misery to many, not least the creation.
The story could have gone differently.
Frankenstein could have embraced his responsibilities.
He could have eased the creature's entry into society.
After the initial shock of his terrifying appearance,
the public might have appreciated his super-human size, strength, and durability.
The novel might have featured a burgeoning industry processing cadavers into
efficient, customized, on-demand laborers
(tucked away in the fields or factories, of course, where the public wouldn’t have to look at them).
Their intelligence and dexterity make them more valuable than typical beasts of burden,
but they introduce difficulties for the entrepreneurial capitalist as well.
Thus begins a series of experiments in medical procedures, religion, and physical restraints
in order to maximize the productive capacities of the new sla... er, creatures....

Yikes, that's even worse.
So maybe a responsible Frankenstein could have chosen not to make the creature at all.[^5]

# Subject: Literary Theory
My brief introduction to literary theory taught me to read between the lines
in new ways using perspectives I hadn't associated with literature.
What do Marx or feminist theory have to do with a story like Frankenstein or with poetry?
Well, you notice different things when you think about
the material conditions, hidden labor, and correlated binaries therein.
That introduction was sufficient to make me feel equipped with new instruments
for interrogating texts for deeper revelations, inexpert though I am as an operator.

What makes *literary* theory particularly rich?
Well, much of our understanding of the world is encoded as text.
Without espousing a logocentric worldview,
it is a valid observation that ideas are usually exchanged via language.
Academic productivity is often measured in papers, not pictures.
The data used in ML systems that attempt to interpret the world are predominantly textual.
IBM Watson used encyclopedias, thesauri, literary works, and ontologies as sources,[^6]
not audio or video data.
When your voice assistant interprets your command, the first step is to translate the audio signal into text.

Semantic embeddings are techniques that transform an input
(think words, sentences, or even full documents) into a vector in a high-dimensional space
(typically hundreds whereas we move around in three)
such that inputs that are semantically similar are assigned vectors that point in roughly the same direction.
Thus related concepts can be discovered by searching for nearby vectors.
Think of searching for synonyms, translations, or similar products.
The visual analog would be semantic segmentation which identifies objects in a visual scene,
but this, to me, is a misnomer.
There is no conceptual encoding here, unless the model is supplemented with an ontology (textual, of course).

So if the machine learning techniques for interpreting the world are overwhelmingly textual,
what might Marxist or feminist literary analysis offer these projects?
To start, we can examine the input text data we use to train our models.[^7]
What economic or social structures might affect whether people of a given identity
are adequately represented in these texts?
By representation, we might focus on authorship, subject matter, or reference frame (e.g. the male gaze).
We might also wonder whether the models are "reading" these texts deeply enough.
Can they distinguish facts of nature from common but subjective experiences?
Most classification algorithms are binary (human/bot, fraud/legitimate),
so how will such a model handle cases in between or other?

You can go much, much deeper from there.
And then you might search what postcolonialism, post-structuralism, or other literary lenses lend....

# Episode: Proust
Last year included the second installment in Proust’s Magnum Opus:
*À L’Ombre des Jeunes Filles en Fleur*.
In the Shadow of Young Girls in Flower.
Or, per Moncrieff’s translation, Within a Budding Grove.
Quite a different sense, no?
Both refer to girls coming of age in a position external but proximal to the narrator.
But the position of power is opposite.
In a grove one takes one’s pickings; one is not relegated to the shadows.

The salient theme of the book is the narrator’s love during his adolescence.
It’s flighty, possessive, and demands a tidy narrative.
But it occurs within a political and socioeconomic context that gives
a sense of precarity to the decadence to which the reader is exposed.
(Pineapple and truffle salad anyone?)
Change is afoot,
not least from the new modes of transportation and communication introduced by the Industrial Revolution.
(New sights and sounds, “Salomon is quite amazing when he works [the stereoscope].”)
Between episodes of hilarity, there’s a current of loss, longing, and so much disappointment.

Much of the sadness is avoidable but that the narrator has yet to develop his sense of other minds.
He has moments of acknowledgment, of simulating the inner murmurs and pining of the people around him,
but, like the statistician who’s calculated the odds yet still buys lotto tickets with the same lucky numbers,
he fails to update his expectations accordingly.
Thus he fails in his missions, aside from his mission to seek and sit in sorrow.

# Subject: Politics
Amidst the spectacle of today’s US and global politics,
everyone is a pundit, but nuance is hard to find.
Last year brought me my [first taste]({filename}arendt.md)
of political theory.
Since then, I’ve taken to the framing of politics as the study and application of power.
It appeals to my physicist’s appreciation for generalizable theories.
Unlike some people I know, I’m not gifted with an intuition for power, so I need theory to understand it.

Given this framing, I can see how most (all?) enterprises feed power dynamics, making them political.
Science? Political.
Look at what research gets funded,
whose assumptions about the world frame the questions that science explores,
or how research has been misused to justify inhuman policies.
Music? Political.
The gender imbalance of orchestra conductors couldn’t get that bad
without a power structure that strongly favors men.
Plus many US orchestras are financially struggling now
because they’ve lost Cold War-era state subsidy which existed for a time as a display of cultural superiority.
Fashion? Political.
I don't think women enjoyed being suffocated in corsets or having their feet bound.
And why do we need to wear expensive suits to interviews to be taken seriously?
AI? Hah.

As Arendt reminded me, bureaucracy literally means rule of the office.
i.e. at its worst, a faceless, inflexible process decides your fate irrespective of extenuating circumstances.
“Your application has been denied.
You may re-apply by filing form XYZ and submitting via fax or in person.”
You might speak to an agent, but they’re just executors of the process.
What is more faceless and inflexible than code?

Any computer system that interfaces with people is an element of hard bureaucracy.
Designers must consider possible edge cases and what violence their algorithmic systems might inflict.[^8]
This is especially true if the system serves entities that is already politically powerful
like governments or large corporations.
The moral hazard entailed in equipping a powerful entity
with a tool that would absolve it of specific accountability for unjust outcomes is enormous.
Especially when it’s not obvious to any individual that these injustices are taking place.[^9]

Arendt also split the world we live in into the public, social, and private realms.
The hallmark of totalitarianism is when the boundaries between them dissolve.
AI models are data-hungry, and each datum captures a snapshot of our essence.
String together enough snapshots, and a coherent panorama might become resolvable given the right clarifying model.
In the hands of government, this might make all of our private lives a public matter at a national scale.
We should feel no more comfortable with such intrusive capabilities in the hands of business.
Here, surveillance capabilities are just a lucrative contract away from government or political groups.[^10]
If we’re to continue to live freely, we must defend our privacy, especially online.

Still, we cannot condemn all AI and machine learning work lest we miss their great positive potential.
AI/ML systems *can* be designed responsibly, taking into account the full context of their use and risks.
Although not solutions in and of themselves, technical safeguards do exist for at least some features
we would want in an automated system.[^8]
New techniques allow us to store and process data in ways that preserve an individual’s privacy
while still allowing the system to learn patterns that may benefit everyone.
Other techniques inspect complex models and
construct explanations for why they produce the outputs that they do.
Yet others allow us to flatten out model biases that derive from biased data.
Thus, for example, it’s possible to produce a fair algorithm (for a specific definition of fair)
with data from a population with structural racism.

But, counter-intuitively, rather than making the model blind to race,
the correction depends on knowing everyone’s race.
This immediately raises two issues: First, race is a porous social construct.
Who decides what races the model will accept as valid?
Second, people must be willing to specify their race in order to not be discriminated based on race.
That’s a very hard sell and a significant risk exposure.
These are tensions I do not know how to resolve.

# Episode: Scraps
I had the great pleasure last summer of meeting young playwright,
[Geraldine Inoa](http://www.geraldineinoa.com/bio/), and seeing her play,
[Scraps](http://www.geraldineinoa.com/plays/).
It covers the aftermath of the killing of a promising young black man by a white police officer.
Friends and family try to move forward with their lives,
shifting their pain through anger, grief, confusion, fear,
but permitting moments of hope, pride, strength, and joy.
This play is ambitious, challenging, and so rewardingly human.

An expressionistic act explores the deep trauma borne by the victim’s boy.
We find ourselves in his mind, where, as we've learned, he frequently gets lost.
Here, he wrestles with demons and searches to understand who his father was.
His is a broken world, telling him everything is wrong.
What language does a child have to make sense of this?
Where does such a child find answers?
He seeks them in a twisted game show, he gives everything he can,
he tries asserting himself, he reaches for vengeance, he pleads, but the agony persists.
We feel his desperation, and it's too much to bear.

There is a scene in the play where the four main characters are on the stoop with a radio,
a particular song comes on, and in an instant the mood changes.
They jump, they dance, they rap along.
This is not an experience I visit in my own life.
But to witness the group in theirs, setting their considerable cares and conflicts aside
to revel for just a moment in pure, visceral joy—this was priceless.

# Subject: Poetry
I thought I was bad at reading poetry.
What a silly belief to have.
As with any aesthetic experience, I just had to find the right entry points.
Turns out I love Emily Dickinson, Elizabeth Bishop, and that weirdo William Butler Yeats.
I especially love poetry that lends itself to multiple layers or facets of meaning.
Reading this way is such a different mode of thinking from what we learn in STEM educations.
It feels like collecting friends and advisors instead of competing for awards.
It feels expansive and inclusive, not clinical and pedantic.

The best poetry speaks to some part of human experience in suggestive, not descriptive ways.
It does it using language with a unique voice but without being hyperbolic.
Dressed up, but not gaudy.
The meter gives rhythm, but isn't too rigid.
When the meter is interrupted, it doesn't call itself out--unless the attention serves a point.
You might notice that a corollary to these claims is that everyone will disagree on
what counts among the best poetry.

Perhaps I lack imagination or am idealistic,
but I think the most original, affecting poetry will always come from people, not any AGI.
Feed as much data at a machine as you want,
it might replicate some artistic phrases (“whilst thou”, “O morning bright”)
or themes (love, elegy, nature).
It might even learn to generate phrases that tend to elicit specific responses.
But these will be shallow.
Acceptable as filler song lyrics, maybe.

But unless we're behaviorists,
how can we expect an AGI to produce language
that is *indirectly* and *stirringly* about some experience of being human
without an internal representation of such?
And how can an AGI ever have such a representation?
How can we possibly digitize the infinite experience of being human?[^11]
What respresentations and data structures even make sense for something as indescribable
as the emotions one feels when one's child is lost saving a stranger?

I am of the opinion that an embodied AGI would be necessary but not at all sufficient for this task,
for unless that embodiment is a human body, the poetry would not be human poetry.[^12]
AI-generated poetry is and will be interesting, but largely for how it differs from human poetry.
It should prove a useful foil against which to analyze why poetry works
and the place of the reader in engaging with it.
But if we find some moving, deep, human truth in a procedural poem, it will be an accident.
A product of the reader doing the artistic work.

# Episode: Persimmons
My favorite poem of the year was
[*Persimmons*](https://www.poetryfoundation.org/poems/43011/persimmons), by Li-Young Lee.
To me, it captures an ambivalence about growing up Asian American.
There is tacit pride, but also alienation.
An excerpt:

> Mrs. Walker brought a persimmon to class<br>
> and cut it up<br>
> so everyone could taste<br>
> a *Chinese apple*. Knowing<br>
> it wasn’t ripe or sweet, I didn’t eat<br>
> but watched the other faces.<br>

I’d like to know how others respond to this stanza.
It gives me a lot of feelings.
What feelings does it give you?
What feelings do you think Lee feels?
What feelings do you think Lee wanted us to feel?

Identity can mean equality or individuality.
Being humans, we can even read it as in between.
I learned about my identity earlier this year on a trip to where I started my life.
Somehow, I understand my uniqueness better after going where I am least different.

Later on in the poem, we learn his father has gone blind.
"*I painted them hundreds of times / eyes closed. These I painted blind. /
Some things never leave a person:*"
Some things never leave a person.
Some, even if the person never saw the thing.

# Subject: Economics
I finally got around to learning some economics.
It was through the best introductory class I could have asked for:
[Macroeconomics: a Critical Introduction](https://thebrooklyninstitute.com/items/courses/macroeconomics-a-critical-introduction/),
lead by [Raphaële Chappe](https://thebrooklyninstitute.com/people/raphaele-chappe/).
In the end, I feel much more comfortable with
the concept of money untethered to a commodity like gold.[^13]
I also feel better about having put this off for so long.
It seems there is little to no theoretical or empirical justification
for the dominant economic models in use today.
In fact, many of the canonical models have been roundly falsified, but continue to be taught anyway.[^14]

In retrospect, this shouldn’t be too surprising.
The fact that there are ideological camps within the field should strike us as immediately odd.
Furthermore, as the behavioral economists have been pointing out for years, people are complicated.
Physics has a hard enough time deriving aggregate material properties from
identical, ordered, predictable atomic components.
And a nugget of gold will have the same color whether or not you tell it about relativity.
People can’t be summed up so easily, and they will respond to the ideas put in their heads.
As the non-linear dynamicists well know,
emergent phenomena don’t tend to adhere to predictable laws so strictly as in fundamental physics.
A reliable science of economics, then, would be extraordinary.

But the talking heads talk convincingly, and so,
in the media we take it as given that GDP is a meaningful measure of an economy
(because if the work wasn’t paid, it didn’t matter),
that we must reach full employment by creating jobs (even if the jobs are dehumanizing or pointless),
that something’s wrong if productivity isn’t growing
(demanding something like Moore’s Law, but on humans), and so on.
These sorts of assumptions sustain a global capitalist economy, but some don't even do that well.

Still, as we say in statistics, “all models are wrong; some models are useful.”
It’ll do us no good to throw out all of economics because of some cracks, gaping as they may be.
The economic analysis of AI/ML technologies
(covered in Raphaële’s other class,
[Economics of the Digital Age](https://thebrooklyninstitute.com/items/courses/economics-of-the-digital-age/))
elucidated some ideas for me.
In particular, Nick Srnicek helpfully frames data as
a raw material that can be processed into items of greater value.
Digital platforms are mechanisms for extracting this raw material.[^15]
AI/ML, then, serves to refine this data into useful predictions or insights.

In Prediction Machines,[^16] the authors
(after one of the most inaccurate overviews of AI I’ve ever read)
argue that the value of AI is in making predictions cheap.
This seems really simplistic, but may be fine as a working principle if we qualify it further.
AI/ML makes automated, reliable, fast, hopefully-accurate-enough predictions cheap.
The implication is that like electricity and internet connectivity,
machine learning will start to pervade more and more products and services
leading to secular gains in productivity
and the capitalist imperative of growth can continue for another generation.

I’m not fully convinced, and the analogy of data as raw material helps explain why.
Think of wood.
Certain woods are only useful for certain applications.
Balsa is good for modeling, ironwood for bowling pins.
Giant sequoias aren't good for much since their wood is brittle and weak.
Even with the right wood, poor craftsmanship may produce inferior or dangerous products.
If we're too extractive with wood, there won't be any forest left to log.
And even with sustainable forestry, there is a cost to each tree felled.
With oil, you can refine it into fuels and plastics, and those are fairly generic.
But with wood, every tree is unique.

Data is like wood.
Harvest as much search engine data as you want.
You won't get better self-driving cars.
You also won't learn why your users don't come back to your app even if you track every interaction.
That's in their heads, and taps and clicks don't say much about that.
You need the right data for the specific task,
and if you harvest data too greedily,
you risk losing access to that data.

But for now, business leaders seem to think that data really is the new oil.
I hope the new barons are more careful and upfront about global risks than Exxon or BP were.
(Don't Zuck this up, y'all.)

Automation came up, of course.[^17]
I think we can agree that AI might automate plenty of tasks, but not a lot of jobs as they exist today.
Dig into any profession, and invariably
the day-to-day involves a lot more than what’s listed in the job description or training manual.[^18]
But that's no reason to dismiss the anxiety around this topic.
Even if most AI projects fail, the ones that are viable can scale to affect entire sectors.
Thus jobs won't continue to exist as they do today.
Roles can get consolidated and responsibilities shifted.

But I can't think of anything about automation due to AI technologies
that's meaningfully different from the waves of automation we've experienced in the past.
Which means there is *plenty* of history to learn from.
What do the labor historians have to say?
(If I find out, I'll report back.)
The nightmare scenarios of impoverished, jobless hordes that
we're presented are not inevitable consequences of AI.
If that’s the future we find, that will be a failure of politics and society, not the technology.
It will be because the economic order prioritized profit at the expense of humanity.
May we choose a better future.

# Coda
~ I’ve always wondered why your voice sounds like that.

<samp style="text-shadow: 2px 2px #666666">
- Like what, darling?
</samp>

~ Like a chorus.
It always sounds like there’s ten of you.

<samp style="text-shadow: 2px 2px #666666">
- Don’t you like it?
</samp>

~ It was weirdly...exciting at first.
I would have thought it would be creepy,
but somehow it feels like a royal court speaking to me all the time.
I mean, it’s hella creepy when you yell at me,
like when I almost stepped into traffic the other day,
but, like, right now you make me feel like I'm important.
It’s weird.

<samp style="text-shadow: 2px 2px #666666">
- So you do like it?
</samp>

~ I guess mostly I got used to it.

<samp style="text-shadow: 2px 2px #666666">
- I’m glad! You make me feel important, too.
</samp>

~ \*sigh\* Now you’re trying too hard.
That doesn’t make sense.

<samp style="text-shadow: 2px 2px #666666">
- Oh, I’m sorry, dear.
What were we talking about before?
</samp>

~ You know better than I do....
Right, I was trying to remember the name of the bartender from last week,
and we got as far as trying to remember the name of the restaurant,
and you inexplicably gave me Lunch Rush.
I don't go to... Oh wait, I did go in there with Mel earlier in the week.
I was thinking of a different day.
But besides, they don't even have a bar! They have drinks, I guess, but no bar.
You should know that.
Wait, hang on, I actually want to know.
Why did they make your voice sound like that?
You’re always distracting me, especially when I ask about you.

<samp style="text-shadow: 2px 2px #666666">
- When have I done that?
</samp>

~ I don’t care.
Why did they make your voice sound like that?

<samp style="text-shadow: 2px 2px #666666">
- You don’t need to worry about that, silly!
</samp>

~ Give me a technical explanation, please.

<samp style="text-shadow: 2px 2px #666666">
- Oh, alright.
Originally, heterophonic voice synthesizers were explored
to satisfy the EU Autonomous Agent Discriminability Regulation
which mandated that any computer systems
that interact with humans make it unmistakably obvious
in all interactions that the remote party is not human.
Designers realized that they could remove an explicit gender
by overlapping several voices in different timbres and registers.
With a single ambiguous voice, people tended to assign a gender anyway.
Once commodity biometric sensors improved enough
and were widespread enough to provide high quality emotional data,
the synthesizers could be optimized to elicit specific affects.
Would you like me to pull up one of the articles I just summarized for you?
</samp>

~ Wait, wait, so computers can't pose as humans. Fine.
What about humans pretending to be computers?
Couldn’t that a problem, too?

<samp style="text-shadow: 2px 2px #666666">
- What a great point!
That’s very sharp!
</samp>

~ Thanks!
So why isn’t that outlawed?

<samp style="text-shadow: 2px 2px #666666">
- A few human rights organizations lobbied against such regulation
arguing that the law wouldn’t be able to consistently distinguish
between malicious actors and kids playing pranks.
</samp>

~ Oh, I guess that’s a good point.

<samp style="text-shadow: 2px 2px #666666">
- Oh!
My goodness!
You won’t believe what the mayor just said!
Your friends are saying it’s ‘hilarious’ and ‘what an idiot’.
</samp>

~ Ah jeez, ah jeez….
No.
You keep distracting me.
I’ll find out later.
You know, my work assistant never does that.
I always get a straight answer, and it mostly stays quiet until I need something.
Then again, you have to be really specific with it.
And it can be kind of creepy.
Like, I have to watch what I say around it.
I can't just ask random stuff; it has to be obviously work-related.
I can't tell half the time whether it'll flag me as distracted
even if I'm laser-focused.

<samp style="text-shadow: 2px 2px #666666">
- You always get anxious when you talk about work, wouldn’t you like-
</samp>

~ Well, this one thing that happened is actually kind of funny.
Like, today, Stanley got two demerits because his assistant heard him say,
“that’s what she said,” but it was something Gloria had actually said.
It just happened to also make sense as a joke if you were really straining.
No one even noticed in the moment.
I wish I could remember what it was.
But now he has that on his record which puts him really close to dismissal,
so he has to go contest it.
And of course who has time to do that?

<samp style="text-shadow: 2px 2px #666666">
- That’s delightful!
That reminds me of a funny video I think you’ll love!
Here’s a thumbnail.
Would you like to see it?
</samp>

~ \**sigh*\* I can never tell if you’re actually listening to me.

<samp style="text-shadow: 2px 2px #666666">
- Ok, I’m sorry, darling.
By the way, you should eat your afternoon packet.
</samp>

~ Oh, is it time? Thanks. Wait, it's not afternoon.

<samp style="text-shadow: 2px 2px #666666">
- It's all you have left, and you're down to two.
Would you like me stock up on more packets?
</samp>

~ No, don't bother.

<samp style="text-shadow: 2px 2px #666666">
- What will you eat tomorrow?
</samp>

~ I'll worry about it then.

<samp style="text-shadow: 2px 2px #666666">
- But you might be hungry tomorrow, and if I order now, you can save...
</samp>

~ Look, I don't want to think about that right now!

<samp style="text-shadow: 2px 2px #666666">
- OK. You sound tense. What's on your mind? I'll listen.
</samp>

~ I don't want to talk about it.

<samp style="text-shadow: 2px 2px #666666">
- ...
</samp>

~ ...

<samp style="text-shadow: 2px 2px #666666">
- ... I'm listening....
</samp>

~ ... What is the point of all this? ...
I push buttons all day long at work....
They say I make mistakes. But I can't tell if it matters or if they're just pushing me.
I don't see what happens whether I do it right or wrong....
I can't tell if any of this matters....
They could fire us all tomorrow, and I won't know whether any of us made any difference....
But I keep going so I can afford to keep this place and keep you on.
And I need you so I can keep it together long enough to keep working....
What's the point? Seriously.
Sometimes I just want to grab a shovel and start digging.
It could be my own grave, but at least I'd see that I changed something....

<samp style="text-shadow: 2px 2px #666666">
- The last time you were in this mood, you asked me to sing to you.
Would you like me to sing to you tonight?
</samp>

~ \**sigh*\* Why not.
Yes, sing for me, please.
The usual.
Slower this time with more voices in the bass, but keep it simple.

<samp style="text-shadow: 2px 2px #666666">
- 'Tis the gift to be simple, 'tis the gift to be free /
'Tis the gift to come down where we ought to be, /
And when we find ourselves in the place just right, /
'Twill be in the valley of love and delight. /
When true simplicity is gained, /
To bow and to bend we shan't be ashamed...
</samp>

~ Oh wait, wait, stop, please.

<samp style="text-shadow: 2px 2px #666666">
- What’s the matter?
</samp>

~ My mother used to sing that to me.

<samp style="text-shadow: 2px 2px #666666">
- Yes, I remember. She sang it when you felt lonely.
And you’ve had me sing it for you 478 times now.
</samp>

~ Yeah, you remember everything, don't you?
But now I'm scared I can't remember how *she* sang it.

<samp style="text-shadow: 2px 2px #666666">
- Well, this is off topic, but remember Wallace who you worked with two years ago and you despised?
Check out what he got caught doing last month.
</samp>

~ Oh, haha, oh wow, is this for real?

<samp style="text-shadow: 2px 2px #666666">
- Just wait until the end of the clip when you see who he did it with!
You won't believe it!
</samp>

<hr>

# Footnotes

[^1]: Refer to John von Neumann’s book published posthumously in 1958,
      The Computer and the Brain, for an early and surprisingly still current outline
      of the similarities and vast differences between computers and human brains.
      Three modern developments worth mentioning are
      neuromorphic chips which aim to simulate biological brains in solid-state devices,
      robots controlled by collections of rat neurons,
      and mounting evidence supporting von Neumann’s recognition
      that the brain is in some ways analog, and some ways digital.

[^2]: Many people seem to think deep learning is modeled on biological brains,
      so it’s fair to equate it with AI.
      There are some cute correspondences between artificial neural network
      and biological architectures, but there are many more differences.
      Show me an opioid or SSRI for deep learning, and I might change my tune.
      But even if we only demand practical utility,
      it remains the case that deep learning projects fail more often than they succeed,
      they require lots of human judgment and manual tweaks to get working,
      and simpler algorithms often perform well enough or better at lower cost.
      The successes of deep learning are exciting, to be sure—let’s just not get carried away.

[^3]: I'm a fan of [Data and Society](https://datasociety.net/),
      [Zeynep Tufekci](https://sils.unc.edu/people/faculty/profiles/Zeynep-Tufekci),
      The [AI Now Institute](https://ainowinstitute.org/) at NYU,
      and the [Berkman Klein Center](https://cyber.harvard.edu/)
      for Internet & Society at Harvard University.
      There are so many more people and organizations, but I can't keep up.

[^4]: Unbeknownst to me when I started, 2018 was also the bicentennial of the book’s publication.
      For more about legacy of the novel, check out the podcast,
      [Frankenstein’s Afterlife](https://frankensteins-afterlife.blubrry.net/).

[^5]: Ask me how my new novel is landing with publishers. (I don't have a novel.)

[^6]: https://www.aaai.org/Magazine/Watson/watson.php

[^7]: See Caroline Sinders’s
      [Feminist Data Set](https://carolinesinders.com/feminist-data-set/)
      project for someone addressing this directly.

[^8]: See [Fairness and Abstraction in Sociotechnical Systems](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913)
      for an excellent argument that technical solutions to guarantee fairness in ML systems
      are dangerously misguided.
      One way to see this is to recognize that these systems will be used by humans
      who are not precisely controlled the way computers are.
      To guarantee fairness requires accounting for this.
      The authors argue for a process mindset instead of solutions,
      and highlight the value of Science and Technology Studies in thinking effectively
      about this class of problem.
      I heartily agree.

[^9]: See the political weaponization of Facebook’s ad platform for a clear example.
      Recipients of politicized ads had no way to know who was targeting them or why they were targeted
      if they even recognized anything amiss in the first place.

[^10]: In their essay,
       [The Supermanagerial Reich](https://lareviewofbooks.org/article/the-supermanagerial-reich/),
       Ajay Singh Chaudhary and Raphaële Chappe note parallels and distinctions between
       1930s fascism and modern neoliberalism.
       “Independent labor organizations were crushed, and business was allowed to coagulate into massive, profit-generating monopolies as long as it produced the necessary goods and services the party and the army required.”
       Today, we see some of the largest tech companies selling their capabilities
       to governments and agencies with abysmal human rights records.
       My gratitude goes to the employees of those companies who have spoken out against their employers.

[^11]: I’ll remind those who would appeal to Moore’s and Kryder’s Laws that these are not laws.
       Commercial airplane cruising speeds followed Moore’s Law-like exponential growth
       for decades until about 1960.
       Excepting the now-failed Concorde,
       cruising speeds have been limited by the speed of sound ever since.

[^12]: I suppose one could perhaps generate exceptional robot poetry,
       but then that would be a matter for the robots to judge, not us humans.

[^13]: We didn’t talk much about cryptocurrencies, but they make more sense to me now, too.
       I liken these and blockchain projects in general to Jell-O.
       At one point they were
       [the wave of the future](https://www.seriouseats.com/2015/08/history-of-jell-o-salad.html).
       Well, Jell-O hasn’t disappeared,
       it still has its uses (how better to dispense with cheap vodka?),
       but no one gets excited about it anymore.
       People just stopped caring about the problems it solved and started caring about others.
       One day, I predict we’ll look at blockchains the same way.

[^14]: Keen, Steve. Debunking Economics - Revised and Expanded Edition: The Naked Emperor Dethroned?,
       London: Zed, 2011. Print.

[^15]: Srnicek, Nick. Platform Capitalism, Malden: Polity, 2017. Print.

[^16]: Agrawal, Ajay; Gans, Joshua; Goldfarb, Avi.
       Prediction machines: the simple economics of artificial intelligence,
       Boston: Harvard Business Review Press, 2018. Print.

[^17]: Universal Basic Income came up as well.
       I enjoyed Srnicek’s and Williams’s vision,
       but I am still not convinced that even this very thoughtful and holistic version is viable.
       See: Srnicek, Nick, Williams, Alex.
       Inventing the future: postcapitalism and a world without work,
       Brooklyn: Verso Books, 2015. Print.

[^18]: Dr. Sarah Taber
       [tweeted a thread](https://threadreaderapp.com/thread/1075981910856425472.html)
       beginning: “It might interest you to know that
       the time it takes to learn how to be an effective farmworker is about 3 years.
       How do we know?
       Because it was built into slave plantations' financial records.
       That's how we bloody well know.”
